# Deepgram μ-law Golden Baseline (P1 Transport Orchestrator enabled)
# Copy to config/ai-agent.yaml to run this baseline, or set it manually on the server.
# Requires DEEPGRAM_API_KEY in .env

# Provider selection
default_provider: "deepgram"

# Transport
audio_transport: "audiosocket"   # audiosocket | externalmedia
downstream_mode: "stream"        # stream | file

audiosocket:
  host: "0.0.0.0"
  port: 8090
  format: "ulaw"                  # wire format for telephony

# Streaming playback (target)
streaming:
  sample_rate: 8000               # downstream target
  jitter_buffer_ms: 120           # 80–150 ms typical; 120 for robust baseline
  keepalive_interval_ms: 5000
  connection_timeout_ms: 10000
  fallback_timeout_ms: 8000
  chunk_size_ms: 20               # P1: provider_pref.preferred_chunk_ms alignment
  min_start_ms: 320               # warm-up buffer (reduce underruns)
  low_watermark_ms: 240           # pause when buffer dips below this
  provider_grace_ms: 500          # absorb late chunks after cleanup
  logging_level: "info"

# Optional VAD/barge-in tuning
barge_in:
  enabled: false
  initial_protection_ms: 400
  min_ms: 400
  energy_threshold: 1800
  cooldown_ms: 1000
  post_tts_end_protection_ms: 250

# Providers
providers:
  deepgram:
    enabled: true
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2-general"
    tts_model: "aura-asteria-en"
    greeting: "${DEEPGRAM_GREETING:-Hello, how can I help you today?}"
    instructions: "${DEEPGRAM_INSTRUCTIONS:-You are a concise voice assistant. Respond in under 20 words and answer immediately.}"
    # Input expectations (STT)
    input_encoding: "linear16"
    input_sample_rate_hz: 8000
    continuous_input: true
    # Output format (TTS)
    output_encoding: "mulaw"
    output_sample_rate_hz: 8000
    # Engine target alignment (TransportCard alignment uses these if present)
    target_encoding: "ulaw"
    target_sample_rate_hz: 8000

# Canonical LLM defaults
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
  model: "gpt-4o"

# P1: Audio profiles and context mapping for Transport Orchestrator
profiles:
  telephony_ulaw_8k:
    internal_rate_hz: 8000
    transport_out:
      encoding: ulaw
      sample_rate_hz: 8000
    provider_pref:
      input:
        encoding: mulaw
        sample_rate_hz: 8000
      output:
        encoding: mulaw
        sample_rate_hz: 8000
      preferred_chunk_ms: 20
    idle_cutoff_ms: 1200
  default: telephony_ulaw_8k

# Contexts (Option A): can set provider/profile; AI_PROVIDER on channel still has highest precedence
contexts:
  sales:
    provider: deepgram
    profile: telephony_ulaw_8k
